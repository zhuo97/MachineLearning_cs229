{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Notation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在讨论 SVM 的时候，出于简化的目的，我们需要引进新的符号来表示分类。假设我们要对一个二分类问题建立一个线性分类器，其中，标签(label)为 $y$，特征(feature)为 $x$。从现在开始，我们使用 $y\\in\\{-1,1\\}$ 来表示类别 (而不是之前的 $y\\in\\{0,1\\}$)。同时，我们也不再使用向量 $\\theta$ 来表示线性分类器的参数，而是使用参数 $w$ 和 $b$，所以，我们的线性分类器为"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "h_{w,b}(x)=g(w^Tx+b)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其中，当 $z\\geq0$ 时，$g(z)=1$；当 $z<0$ 时，$g(z)=-1$。这里的参数 \"$w,b$\" 可以让我们把截距项(intercept term) $b$ 和其他参数分开。（此外，我们不需要像之前那样设定 $x_0=1$。）因此，这里的参数 $b$ 就相当于之前的 $\\theta_0$，而参数 $w$ 则相当于 $[\\theta_1,\\cdots,\\theta_n]^T$。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "需要注意的是，根据我们对函数 $g$ 的定义，我们的分类器会直接预测类别是1或者-1（参考感知机算法 perceptron algorithm ），这样也就不需要经过中间步骤来估计 $y$ 为1的概率。（这里的中间步骤指的是逻辑回归的步骤）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Functional and geometric margins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "给定一个训练样本 $(x^{(i)},y^{(i)})$，我们定义该训练样本的函数间隔(functional margin)为"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\hat{\\gamma}^{(i)}=y^{(i)}(w^Tx^{(i)}+b)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意到，为了使函数间隔尽可能大（也就是说，为了让我们的预测是正确的且有着高的确信度），当 $y^{(i)}=1$ 时，我们需要尽可能地使 $w^Tx^{(i)}+b$ 是一个大的正数。相反，当 $y^{(i)}=-1$ 时，我们需要让 $w^Tx^{(i)}+b$ 尽可能是一个大的负数。而且，如果 $y^{(i)}(w^Tx+b)>0$，则说明我们对这个训练样本的预测是正确的。因此，一个大的函数间隔代表着一个正确且有着高确信度的预测。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "给定一个训练集 $S=\\{(x^{(i)},y^{(i)}),i=1,\\cdots,m\\}$，我们定义该训练集的函数间隔为所有训练样本的函数间隔的最小值。记为 $\\hat{\\gamma}$，即"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "$$\n",
    "\\hat{\\gamma}=\\min_{i=1,\\cdots,m}\\hat{\\gamma}^{(i)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于一个线性分类器，选择上面给定的函数 $g$ (取值范围为 $\\{-1,1\\}$)。我们注意到函数间隔有一个性质，使得它不能够很好地衡量确信度。如果我们将 $w$ 和 $b$ 换成 $2w$ 和 $2b$，那么由于 $g(w^Tx+b)=g(2w^Tx+2b)$，这将不会改变 $h_{w,b}(x)$。也就是说，函数 $g$ 和 $h_{w,b}(x)$ 只取决于 $w^Tx+b$ 的正负符号(sign)，但不受其数值大小(magnitude)的影响。但是，把 $(w,b)$ 替换成 $(2w,2b)$ 会导致函数间隔被放大了两倍。换句话说，成比例地缩放 $w$ 和 $b$ 后，超平面(hyperplane)并没有变化，而函数间隔却变化了。直观地看，这导致我们需要引入某种归一化条件，例如，$\\Vert{w}\\Vert=1$。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "因此，给定一个训练样本 $(x^{(i)},y^{(i)})$ 我们定义该训练样本的几何间隔(geometric margins)为"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "$$\n",
    "\\gamma^{(i)}=y^{(i)}\\left( \\left(\\frac{w}{\\Vert{w}\\Vert} \\right)^Tx^{(i)}+\\frac{b}{\\Vert{w}\\Vert} \\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "这样，当我们成比例地缩放 $w$ 和 $b$ 的时候，几何间隔的大小是不变的。值得注意的是，正是这种对参数缩放的不变性，当我们试图对某个训练集拟合 $w$ 和 $b$ 的时候，我们可以对 $w$ 添加任意的缩放约束。例如，我们可以要求 $\\Vert{w}\\Vert=1，\\left|w_1\\right|=5，\\left|w_1+b\\right|+\\left|w_2\\right|=2$ 等等，这些都只要对 $w$ 和 $b$ 进行成比例的缩放就可以满足了。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后，给定一个训练集 $S=\\{(x^{(i)},y^{(i)}),i=1,\\cdots,m\\}$，我们也可以定义该训练集的几何间隔为所有训练样本的几何间隔的最小值。记为 $\\gamma$，即"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\gamma=\\min_{i=1,\\cdots,m}\\gamma^{(i)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最后，根据函数间隔和几何间隔的定义可知，函数间隔和几何间隔有如下关系："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "\\gamma^{(i)} &= \\frac{\\hat\\gamma^{(i)}}{\\Vert{w}\\Vert} \\\\\n",
    "\\gamma &= \\frac{\\hat\\gamma}{\\Vert{w}\\Vert} \n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**小结**："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们的目的是要建立一个最大间隔分类器。具体地说，我们希望最大化整个训练集的间隔，而整个数据集的间隔被定义为所有训练样本间隔的最小值。而之所以不采用函数间隔来衡量训练样本到超平面的距离，是因为对于任意一个成功划分训练样本的超平面来说，我们只要成比例地放大 $w$ 和 $b$ 就可以让函数间隔任意大。这样我们就无法找到最优的超平面。因此，我们使用几何间隔来衡量训练样本到超平面的距离。而几何间隔其实就是高中学的点到直线距离的推广。而由于几何间隔对于参数缩放的不变性，使得我们下面可以使用这个性质简化我们的问题。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
