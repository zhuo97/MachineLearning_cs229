{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Kernels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里简单地介绍一下核函数，受限于所学，以下的内容可能存在着错误或者理解上的偏差。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们知道，Logistic Regression 的决策边界 (decision boundary) 是线性的，如果我们希望得到非线性的决策边界，我们可以通过 feature mapping 的方式，把数据从低维映射到高维。这里我们用 $\\phi$ 来表示 feature mapping。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意到，我们在之前的讨论中，我们将算法以内积的形式写出，即 $<x^{(i)},x^{(j)}>$。如果我们想要得到非线性的决策边界，就需要先通过 $\\phi$ 把 $x$ 从低维空间映射到高维空间得到 $\\phi(x)$，然后计算 $<\\phi(x^{(i)}),\\phi(x^{(j)})>$。可以看到，这样的计算是非常耗时的，特别是当我们映射到的高维空间的维度非常高的情况下。因此，我们就希望找到一种方式把上述步骤合为一步。具体地说，我们希望我们可以不用显示地表示 $\\phi(x)$，就能够得到 $<\\phi(x^{(i)}),\\phi(x^{(j)})>$ 的计算结果，从而降低计算复杂度。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "先来看一个例子，假设我们对 $x\\in\\mathcal{R}^d$ 进行二次多项式转换 (2nd order polynomial transform) 即："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\phi_2(x)=(1,x_1,\\cdots,x_d,x_1^2,x_1x_2,\\cdots,x_1x_d,x_2x_1,x_2^2,\\cdots,x_2x_d,\\cdots,x_d^2)^T\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后我们计算 $<\\phi_2(x),\\phi_2(x^{'})>$ ( 为了避免符号的混乱，接下来用 $x$ 和 $x^{'}$ 代替 $x^{(i)}$ 和 $x^{(j)}$)，即 $\\phi_2(x)^T\\phi_2(x^{'})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "\\phi_2(x)^T\\phi_2(x^{'})\n",
    "&=1+\\sum^d_{i=1}x_ix^{'}_i+\\sum^d_{i=1}\\sum^d_{j=1}x_ix_jx^{'}_ix^{'}_j \\\\\n",
    "&=1+\\sum^d_{i=1}x_ix^{'}_i+\\sum^d_{i=1}x_ix^{'}_i\\sum^d_{j=1}x_jx^{'}_j \\\\\n",
    "&=1+x^Tx^{'}+(x^Tx^{'})(x^Tx^{'})\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "于是，我们发现，通过计算 $1+x^Tx^{'}+(x^Tx^{'})(x^Tx^{'})$ 就可以得到 $\\phi_2(x)^T\\phi_2(x^{'})$ 的结果。而且这样的计算方式，不需要我们具体地写出 $\\phi(x)$，然后再计算内积。因此，这样的方法的计算复杂度更低。其实 $K_{\\phi_2}(x,x^{'})=1+x^Tx^{'}+(x^Tx^{'})(x^Tx^{'})=\\phi_2(x)^T\\phi_2(x^{'})$ 就是核函数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由此，我们给出核函数的定义："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "设 $\\mathcal{X}$ 是输入空间（欧式空间 $\\mathcal{R}^n$ 的子集或离散集合），又设 $\\mathcal{H}$ 为特征空间（希尔伯特空间），如果存在一个从 $\\mathcal{X}$ 到 $\\mathcal{H}$ 的映射"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\phi(x):\\mathcal{X}\\to\\mathcal{H}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使得对所有的 $x,z\\in\\mathcal{X}$，函数 $K(x,z)$ 满足条件"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "K(x,z)=<\\phi(x),\\phi(z)>\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "则称 $K(x,z)$ 为核函数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，我们介绍两个常用的核函数，一个是多项式核，另一个是高斯核。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Polynomial Kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对上面举例的二次多项式转换，我们可以进行以下推广："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "\\phi_2(x)=(1,x_1,\\cdots,x_d,x_1^2,\\cdots,x_d^2)&\\Leftrightarrow K_{\\phi_2}(x,x^{'})=1+x^Tx^{'}+(x^Tx^{'})^2 \\\\\n",
    "\\phi_2(x)=(1,\\sqrt{2}x_1,\\cdots,\\sqrt{2}x_d,x_1^2,\\cdots,x_d^2)&\\Leftrightarrow K_{\\phi_2}(x,x^{'})=1+2x^Tx^{'}+(x^Tx^{'})^2 \\\\\n",
    "\\phi_2(x)=(1,\\sqrt{2\\gamma}x_1,\\cdots,\\sqrt{2\\gamma}x_d,x_1^2,\\cdots,x_d^2)&\\Leftrightarrow K_{\\phi_2}(x,x^{'})=1+2\\gamma x^Tx^{'}+\\gamma^2(x^Tx^{'})^2\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "总结一下，即"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "K_2(x,x^{'})=(1+\\gamma x^Tx^{'})^2\\quad with\\,\\gamma>0\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们看到，不同的 $\\gamma$ 对应不同的 $\\phi_2(x)$。那么这些 $\\phi_2(x)$ 存在着什么样的区别呢？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们看到它们最后计算的结果是不一样的，也就是说它们定义了不同的内积。在一个内积空间中，不同的内积就代表不同的距离。而不同的距离就意味着有不同的几何特性，这样计算出来的间隔 (margin) 就不一样。采用不同的转换，虽然在看似同样的空间，但是会得到可能不同的边界。具体如下图所示："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![avatar](./image/image2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们还可以对上式接着进行推广："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "K_2(x,x^{'})&=(\\zeta+\\gamma x^Tx^{'})^2\\quad with\\,\\gamma>0,\\zeta\\geq0 \\\\\n",
    "K_3(x,x^{'})&=(\\zeta+\\gamma x^Tx^{'})^3\\quad with\\,\\gamma>0,\\zeta\\geq0 \\\\\n",
    "\\vdots \\\\\n",
    "K_Q(x,x^{'})&=(\\zeta+\\gamma x^Tx^{'})^Q\\quad with\\,\\gamma>0,\\zeta\\geq0\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最终得到多项式核，我们可以看到，线性核其实是多项式核的特殊情况。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "K_1(x,x^{'})&=(0+1\\cdot x^Tx^{'})^1 \\\\\n",
    "\\vdots \\\\\n",
    "K_Q(x,x^{'})&=(\\zeta+\\gamma x^Tx^{'})^Q\\quad with\\, \\gamma>0,\\zeta\\geq0\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Gaussian Kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "既然核函数可以让我们不需要写出 $\\phi(x)$，就可以得到 $\\phi(x)^T\\phi(x^{'})$ 的计算结果。那么我们能否找到一个核函数，对应的是无穷维度的特征映射 $\\phi$ 呢？其中一个就是我们要介绍的高斯核，高斯核函数的定义如下："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "K(x,x^{'})=exp\\left(-\\gamma\\Vert x-x^{'}\\Vert^2\\right)\\quad with \\,\\gamma>0\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后，我们可以证明（这里假设 $\\gamma=1$）："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "K(x,x^{'})&=\n",
    "exp\\left( -\\Vert x-x^{'}\\Vert^2 \\right) \\\\\n",
    "&=exp\\left( -(x-x^{'})^T(x-x^{'}) \\right) \\\\\n",
    "&=exp\\left( -x^Tx-x^{'T}x^{'}+2x^Tx^{'} \\right) \\\\\n",
    "&=exp\\left( -\\Vert x \\Vert^2 \\right)exp\\left( -\\Vert x^{'} \\Vert^2 \\right)exp\\left( 2x^Tx^{'} \\right)\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里根据泰勒公式："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "e^x=\\sum_{n=0}^{\\infty}\\frac{x^n}{n!}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可得："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "K(x,x^{'})\n",
    "&=exp\\left( -\\Vert x \\Vert^2 \\right)exp\\left( -\\Vert x^{'} \\Vert^2 \\right)exp\\left( 2x^Tx^{'} \\right) \\\\\n",
    "&=exp\\left( -\\Vert x \\Vert^2 \\right)exp\\left( -\\Vert x^{'} \\Vert^2 \\right)\\left( \\sum^{\\infty}_{n=0}\\frac{(2x^Tx^{'})^n}{n!} \\right)\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里我们可以看到 $exp\\left( -\\Vert x \\Vert^2 \\right)exp\\left( -\\Vert x^{'} \\Vert^2 \\right)$ 为常数。而 $\\sum^{\\infty}_{n=0}\\frac{(2x^Tx^{'})^n}{n!}$ 其实是对无穷个不同维度的多项式核求和。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果 $x,x^{'}\\in\\mathcal{R}$，上式可以写成:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "K(x,x^{'})&=\n",
    "exp\\left(-(x)^2\\right)exp\\left(-(x^{'})^2\\right)\\left( \\sum^{\\infty}_{n=0}\\frac{(2xx^{'})^n}{n!} \\right) \\\\\n",
    "&=\\sum^{\\infty}_{n=0}\\left( exp\\left(-(x)^2\\right)exp\\left(-(x^{'})^2\\right)\\sqrt{\\frac{2^n}{n!}}\\sqrt{\\frac{2^n}{n!}}(x)^n(x^{'})^n \\right) \\\\\n",
    "&=\\phi(x)^T\\phi(x^{'})\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其中，"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\phi(x)=exp\\left( -x^2 \\right)\\cdot\\left(1,\\sqrt{\\frac{2}{1!}}x,\\sqrt{\\frac{2^2}{2!}}x^2,\\cdots\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到，高斯核对应了一个无穷维度的特征映射 $\\phi$。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们换个角度来进行理解，高斯核其实是对 $x$ 和 $x^{'}$ 相似度 (similarity) 很好的度量，当 $x$ 与 $x^{'}$ 距离越近时，函数值越接近1；当 $x$ 与 $x^{'}$ 距离越远时，函数值越接近0。（其实向量之间的内积 (inner product) 就是对两个向量相似度的度量，而核函数是在隐式地计算两个向量在高维空间的内积，也可以看做是度量两个向量的相似度。）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果我们在 SVM 中使用高斯核，当我们要进行预测时，我们计算："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "w^Tx+b&=\n",
    "\\sum^m_{i=1}\\alpha_iy^{(i)}K(x,x^{(i)})+b\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因为除了支持向量外，其他训练样本对应的 $\\alpha_i=0$。所以我们可以把 $\\sum_{i=1}^m$ 写成 $\\sum_{SV}$ 表示只对支持向量进行求和，SV 指 support vector。所以"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "w^Tx+b\n",
    "&=\\sum_{SV}\\alpha_iy^{(i)}K(x,x^{(i)})+b \\\\\n",
    "&=\\sum_{SV}\\alpha_iy^{(i)}exp\\left( -\\gamma\\|x-x^{(i)}\\|^2 \\right)\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们看到上式其实就是在求中心在支持向量的高斯核的线性组合。基于这个特性，也有人称高斯核为 Radial Basis Function (RBF) kernel。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，我们来看看不同 $\\gamma$ 取值的效果："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![avatar](./image/image3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们也可以把高斯核函数写成如下形式："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "K(x,x^{'})=exp\\left( -\\frac{\\|x-x^{'}\\|^2}{2\\sigma^2} \\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以看到，当 $\\gamma=100$ 时，每个图标 x 就像一个小岛一样。因为 $\\gamma$ 变大的时候就相当于标准差变小了，我们的高斯核函数就变“尖“了。而由于最后的结果是”尖尖“的高斯核函数的线性组合，就得到了图中的结果。所以，$\\gamma$ 的取值需要仔细地进行选择，否则有可能会过拟合。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最后，我们可以看到当 $\\gamma\\to\\infty$ 时，高斯核函数就会变成："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "K(x,x^{'})=1\\{x=x^{'}\\}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当 $x\\neq x^{'}$ 时，$K(x,x^{'})=0$；当 $x=x^{'}$ 时，$K(x,x^{'})=1$。此时，高斯核函数就是确定输入的 $x$ 是否等于某个支持向量。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Mercer's Theorem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "那么给定某个函数 $K$，我们怎么样才能确定这个函数是一个有效的核(valid kernel)呢？换句话说，我们怎么样才能确定存在着某一个特征映射 $\\phi$，使得对于所有的 $x$ 和 $z$，都有 $K(x,z)=\\phi(x)^T\\phi(z)$ ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "假设 $K$ 是一个有效的核，对应着某种特征映射 $\\phi$。考虑某个有 $m$ 个点的有限集合 $\\{x^{(1)},\\cdots,x^{(m)}\\}$（这个集合不一定是训练集）。然后设 $K$ 为 $m\\,\\times\\,m$ 的矩阵，其第 $(i,j)$ 个值 $K_{ij}=K(x^{(i)},x^{(j)})$，我们称矩阵 $K$ 为核矩阵(kernel matrix)。这里对符号 $K$ 进行了重复使用，既指代核函数 $K(x,z)$，也指代核矩阵 $K$，因为这两者有非常明显的关系。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果 $K$ 是一个有效的核，那么就有:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "K_{ij}=K(x^{(i)},x^{(j)})=\\phi(x^{(i)})^T\\phi(x^{(j)})=\\phi(x^{(j)})^T\\phi(x^{(i)})=K(x^{(j)},x^{(i)})=K_{ji}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这就说明 K 是一个对称矩阵。此外，设 $\\phi_k(x)$ 表示向量 $\\phi(x)$ 的第 $k$ 个坐标值(k-th coordinate)。我们发现对任意的向量 $z$，我们有： "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "z^TKz\n",
    "&=\\sum_i\\sum_jz_iK_{ij}z_j \\\\\n",
    "&=\\sum_i\\sum_jz_i\\phi(x^{(i)})^T\\phi(x^{(j)})z_j \\\\\n",
    "&=\\sum_i\\sum_jz_i\\sum_k\\phi_k(x^{(i)})\\phi_k(x^{(j)})z_j \\\\\n",
    "&=\\sum_k\\sum_i\\sum_jz_i\\phi_k(x^{(i)})\\phi_k(x^{(j)})z_j \\\\\n",
    "&=\\sum_k\\left( \\sum_iz_i\\phi_k(x^{(i)}) \\right)^2 \\\\\n",
    "&\\geq0\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由于 $z$ 是任意的，这说明矩阵 K 是半正定(positive semi-definite)矩阵。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这样，我们就证明了，如果 $K$ 是一个有效的核，那么对应的核矩阵 $K\\in\\mathcal{R}^{m\\times m}$ 是一个半正定矩阵。实际上，这不仅仅是必要条件，也是一个充分条件。我们也称一个有效的核为 Mercer kernel。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，我们给出 Mercer 定理，很多教材对该定理的描述要更复杂一些，里面牵涉到 $L^2$ 函数，但如果输入属性(input attributes)只在实数域 $\\mathcal R^n$ 取值，那么这里给出的表述也是等价的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Theorem (Mercer)**: 给定函数 $K$: $\\mathcal{R}^n\\times\\mathcal{R}^n\\to\\mathcal{R}$。要使 $K$ 是一个有效的核(Mercer kernel)，其充分必要条件为：对任意的 $\\{x^{(1)},\\cdots,x^{(m)}\\}(m<\\infty)$，都有对应的核矩阵为半正定矩阵。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当然，核技巧(kernel trick)用法远远不仅限于 SVM 算法。它在其他方面有着广泛的运用。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Regularization and the non-separable case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参考资料：\n",
    "1. 吴恩达，cs229 讲义\n",
    "2. 林轩田，机器学习技法\n",
    "3. 李航，《统计学习方法》"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
